# Santiago Factory — Architecture Plan (v3)

**Prepared by:** GPT-5
**Date:** 2025-11-16
**Version:** 3.0

---

## Executive Summary

NuSy will operate as a factory that manufactures specialized "Santiagos" (domain agents) on demand. We start with a temporary "fake team" of MCP proxies to accelerate delivery, use them to build the factory core (Navigator, Catchfish, Fishnet), then progressively replace proxies with real, factory-generated Santiagos once they reach ≥90% parity in A/B tests. This approach converts vision into a governed, evidence-driven pipeline: catch knowledge fast, validate behavior via BDD, generate MCP tooling, deploy on DGX for cost-efficient concurrency, and continuously improve using measured feedback.

---

## Current State (Ground Truth)

- The repository contains strong patterns and evidence but lacks the factory shell:
  - `santiago-pm/` documents expedition/tackle/voyage patterns and the 10-step "Old Man and the Sea" workflow.
  - `nusy_prototype/` demonstrates a 4-layer extraction model (30–60 minutes per source, 3 validation cycles) that we will generalize beyond healthcare.
  - `ocean-research/building-on-DGX/` establishes DGX Spark constraints and a practical deployment envelope (shared model hosting via vLLM/TensorRT-LLM, tiered NVMe storage).
  - Missing elements include a canonical `knowledge/` area for catches, MCP proxies for a fake team, and production-grade Navigator/Catchfish/Fishnet.

---

## Target Architecture (Factory Pattern)

### Phase 0 — Fake Team (MCP Proxies)

- Thin MCP services (per role) forward requests to external models and record provenance.
- Purpose: quickly field a working crew capable of executing expedition-style workflows and building the factory.
- Location: `santiago_core/agents/_proxy/` with role instructions in `knowledge/proxy-instructions/`.

### Phase 1 — Factory Core (Built by Fake Team)

- Implement three core components under a single package (see Folder Layout):
  - **Navigator:** Orchestrates the 10-step fishing process from `santiago-pm/strategic-charts/Old man and the sea.md`, enforces 3–5 validation cycles, and records decisions/hypotheses.
  - **Catchfish:** Converts raw sources into a structured 4-layer package with timing and provenance. Baseline 30–60 minutes per source; optimize toward <15 minutes.
  - **Fishnet:** Generates BDD scenarios from the knowledge graph and emits an MCP manifest for the newly caught Santiago.
- All knowledge graph (KG) mutations flow through a queued pipeline with schema validation and ethics/concurrency checks to prevent corruption.

### Phase 2 — First Catch and Replacement

- Run the first fishing expedition to produce a real `santiago-pm` from sources like SAFe and XP.
- Validate via BDD (≥95% pass rate target) and A/B test against the fake PM on canonical tasks.
- If real ≥90% parity, retire the PM proxy and route traffic to the new MCP service.

### Phase 3 — Progressive Replacement

- Repeat Phase 2 for Architect, Developer, QA, UX, and Platform roles.
- Maintain hybrid routing where evidence is ambiguous; replace only when parity thresholds are sustained.

### Phase 4 — Self-Sustaining Operation

- Real Santiagos propose factory improvements (e.g., Catchfish parallelization, smarter schema validation).
- Changes ship via the same expedition/tackle/voyage pattern with measurable deltas (latency, quality, cost).

---

## Key Components

### Navigator

- Encodes the 10-step fishing workflow end-to-end: source intake → extraction → ontology/schema → KG changes → BDD generation → validation loops → deployment → learning.
- Guarantees governance by requiring validation cycles, collecting metrics, and writing expedition logs.

### Catchfish

- Implements the 4-layer extraction pipeline proven by `nusy_prototype/`:
  - Layer 1: raw text/artifacts
  - Layer 2: entities/relations
  - Layer 3: structured Markdown/YAML
  - Layer 4: queued KG mutations
- Emits provenance (source hash, timestamps, agent ID, hypotheses).

### Fishnet

- Reads the KG and writes:
  - BDD scenarios that define expected agent behavior (stored as `.feature` files)
  - `mcp-manifest.json` that exposes the real Santiago’s tools and guardrails
- Associates tests with knowledge artifacts to enable traceability and regression.

### Knowledge Storage

- `knowledge/catches/<santiago-name>/` contains:
  - `domain-knowledge/` (Layer 3)
  - `bdd-tests/` (Fishnet)
  - `mcp-manifest.json` (Fishnet)
  - `provenance.yaml` (Navigator/Catchfish/Fishnet events)
- `knowledge/catches/index.yaml` acts as a trust registry (parity %, last validation, capabilities).

---

## MCP Integration

- All fake/real Santiagos run as MCP services with consistent capabilities and logging.
- Manifests for real Santiagos are generated by Fishnet; fake proxies are hand-authored and simpler.
- The Orchestrator discovers services via the `knowledge/catches/index.yaml` registry to enable dynamic routing and safe rollouts.

---

## DGX Deployment (Shared Inference)

- Host a shared instruction-tuned model (e.g., Mistral-7B) on DGX Spark using vLLM/TensorRT-LLM for batched, low-latency inference.
- Storage tiers:
  - Hot: internal NVMe (working models and active catches)
  - Warm: external NVMe RAID (historical catches, experiment data)
- Observability: GPU/memory metrics via Prometheus; logs via Loki.

---

## Ethics & Concurrency Gating

- Centralized gating via the Orchestrator:
  - Ethics pre-check for tool calls (licensing, usage constraints, organizational policy).
  - Concurrency controls: session isolation, tool locking, and queued writes for all KG mutations.
- Validate at each milestone using multi-agent test plans (e.g., P95 < 6s under 10 concurrent agents; zero KG corruption).

---

## References Cited (Canonical Sources)

- `ocean-research/00-ARCHITECTURE-PATTERN.md`
- `ocean-research/building-on-DGX/dgx_spark_nusy_report.md`
- `santiago-pm/strategic-charts/Old man and the sea.md`
- `santiago-pm/` (expeditions, tackle, voyage-trials)
- `nusy_prototype/` (4-layer extraction; 30–60 min; 3-cycle validation)
