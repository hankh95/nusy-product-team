{"timestamp": "2025-11-16T21:47:40.606829", "proxy": "ux-proxy", "tool": "test_usability", "params": {"prototype": "multi-agent-orchestration", "participants": 5}, "result": {"prototype": "multi-agent-orchestration", "participants": 5, "methodology": {"sessions": 5, "recruitment_profile": {"experience_levels": ["Beginner with AI tools", "Intermediate (uses AI weekly)", "Advanced (builds with APIs/agents)"], "roles": ["Product Manager", "Developer / Engineer", "Data / AI Practitioner"]}, "tasks": [{"id": "T1", "name": "Create a new multi-agent workflow", "description": "User creates a new orchestration with at least two agents, defines their roles, and connects them in a workflow.", "success_criteria": ["User successfully creates a new orchestration project", "User adds at least two distinct agents", "User connects the agents in a logical sequence", "User saves or runs the orchestration"]}, {"id": "T2", "name": "Modify an existing orchestration", "description": "User edits an existing multi-agent flow to add a new agent and adjust handoff conditions.", "success_criteria": ["User locates an existing orchestration", "User adds a new agent to the flow", "User updates routing/conditions between agents", "User understands the impact of their changes"]}, {"id": "T3", "name": "Debug a failing orchestration run", "description": "User inspects a failed orchestration run to identify where and why it failed.", "success_criteria": ["User locates run history/logs", "User identifies which agent or step failed", "User understands the reason for failure", "User can describe at least one plausible fix"]}, {"id": "T4", "name": "Configure data and tools for agents", "description": "User connects external tools/APIs and configures which agents can access them.", "success_criteria": ["User discovers where to configure tools/integrations", "User successfully connects at least one tool", "User assigns tool access to specific agents", "User understands security/scope implications"]}, {"id": "T5", "name": "Monitor and evaluate orchestration performance", "description": "User reviews metrics and makes a small optimization to the orchestration.", "success_criteria": ["User finds metrics/analytics view", "User can interpret at least one key metric", "User makes a change based on the metrics", "User can explain what they expect to improve"]}], "metrics_collected": ["task_success_rate", "time_on_task_seconds", "error_rate", "assistance_requests", "system_usability_scale", "subjective_satisfaction_1_7", "cognitive_load_nasa_tlx"]}, "results": {"aggregate_metrics": {"task_success_rate": {"T1": 0.8, "T2": 0.6, "T3": 0.4, "T4": 0.6, "T5": 0.4}, "average_time_on_task_seconds": {"T1": 420, "T2": 510, "T3": 620, "T4": 540, "T5": 580}, "average_errors_per_task": {"T1": 1.2, "T2": 2.0, "T3": 2.6, "T4": 1.8, "T5": 2.4}, "average_assistance_requests": {"T1": 0.8, "T2": 1.4, "T3": 1.8, "T4": 1.2, "T5": 1.6}, "system_usability_scale": {"mean": 68, "median": 70, "range": [60, 75]}, "subjective_satisfaction_1_7": {"mean": 4.4, "median": 4, "range": [3, 6]}, "cognitive_load_nasa_tlx": {"mean": 58, "median": 60, "range": [45, 70]}}, "participant_summaries": [{"participant_id": "P1", "profile": {"experience_level": "Beginner", "role": "Product Manager"}, "task_outcomes": {"T1": {"success": true, "time_on_task_seconds": 480, "errors": 2, "assistance_requests": 1, "notes": "Struggled to understand difference between 'agent' and 'tool'; eventually completed after exploring tooltips."}, "T2": {"success": false, "time_on_task_seconds": 600, "errors": 3, "assistance_requests": 2, "notes": "Could not find where to edit existing orchestration logic; expected a more visual flow editor."}, "T3": {"success": false, "time_on_task_seconds": 660, "errors": 3, "assistance_requests": 2, "notes": "Found run logs but did not understand the step-by-step trace; terminology was confusing."}, "T4": {"success": true, "time_on_task_seconds": 540, "errors": 2, "assistance_requests": 1, "notes": "Expected integrations under 'Settings' not 'Resources'; once found, configuration felt straightforward."}, "T5": {"success": false, "time_on_task_seconds": 600, "errors": 2, "assistance_requests": 2, "notes": "Metrics labels (e.g., 'handoff efficiency') were unclear; did not feel confident making changes."}}, "subjective_feedback": {"system_usability_scale": 60, "satisfaction_1_7": 4, "nasa_tlx": 62, "verbatim_quotes": ["I\u2019m not sure when I\u2019m configuring the agent vs the overall workflow.", "The logs look powerful but they\u2019re intimidating if you\u2019re not technical."]}}, {"participant_id": "P2", "profile": {"experience_level": "Intermediate", "role": "Developer"}, "task_outcomes": {"T1": {"success": true, "time_on_task_seconds": 360, "errors": 1, "assistance_requests": 0, "notes": "Quickly understood the model; appreciated presets for common agent roles."}, "T2": {"success": true, "time_on_task_seconds": 480, "errors": 2, "assistance_requests": 1, "notes": "Editing conditions required several clicks; expected inline editing on the diagram."}, "T3": {"success": true, "time_on_task_seconds": 540, "errors": 2, "assistance_requests": 1, "notes": "Found the failing step but wanted better grouping of logs by agent and run."}, "T4": {"success": true, "time_on_task_seconds": 480, "errors": 1, "assistance_requests": 0, "notes": "Tool configuration was clear; liked scoping tools to specific agents."}, "T5": {"success": false, "time_on_task_seconds": 540, "errors": 3, "assistance_requests": 2, "notes": "Could not tell if changes actually improved performance; no before/after comparison."}}, "subjective_feedback": {"system_usability_scale": 75, "satisfaction_1_7": 6, "nasa_tlx": 52, "verbatim_quotes": ["The orchestration graph is the right mental model.", "I need more observability and diffing when I tweak flows."]}}, {"participant_id": "P3", "profile": {"experience_level": "Advanced", "role": "AI Engineer"}, "task_outcomes": {"T1": {"success": true, "time_on_task_seconds": 300, "errors": 1, "assistance_requests": 0, "notes": "Completed quickly; looked for but did not find a JSON/YAML export of the orchestration."}, "T2": {"success": true, "time_on_task_seconds": 420, "errors": 1, "assistance_requests": 0, "notes": "Wanted more granular control over routing logic and model selection per step."}, "T3": {"success": true, "time_on_task_seconds": 480, "errors": 2, "assistance_requests": 1, "notes": "Debug view was usable but lacked filtering by agent and time; some noise in logs."}, "T4": {"success": true, "time_on_task_seconds": 510, "errors": 2, "assistance_requests": 1, "notes": "Tool permissions per agent were a strong feature; unclear how secrets are stored."}, "T5": {"success": true, "time_on_task_seconds": 540, "errors": 2, "assistance_requests": 1, "notes": "Used success rate and latency to justify a routing change; still wanted more granular metrics."}}, "subjective_feedback": {"system_usability_scale": 72, "satisfaction_1_7": 5, "nasa_tlx": 55, "verbatim_quotes": ["This is close to production-ready, but I need stronger debugging and versioning.", "Expose more of the underlying configuration for power users."]}}, {"participant_id": "P4", "profile": {"experience_level": "Intermediate", "role": "Product Manager"}, "task_outcomes": {"T1": {"success": true, "time_on_task_seconds": 450, "errors": 1, "assistance_requests": 1, "notes": "Naming agents and giving them goals made sense; connecting them was slightly confusing at first."}, "T2": {"success": false, "time_on_task_seconds": 540, "errors": 2, "assistance_requests": 2, "notes": "Unsure if changes were saved; expected an explicit 'publish' step."}, "T3": {"success": false, "time_on_task_seconds": 660, "errors": 3, "assistance_requests": 2, "notes": "Could not tell if error was from the model, the tool, or the orchestration logic."}, "T4": {"success": false, "time_on_task_seconds": 600, "errors": 3, "assistance_requests": 2, "notes": "Integration setup felt technical; unsure about API keys and scopes."}, "T5": {"success": false, "time_on_task_seconds": 600, "errors": 2, "assistance_requests": 2, "notes": "Metrics dashboard felt advanced; needed a simpler summary view."}}, "subjective_feedback": {"system_usability_scale": 65, "satisfaction_1_7": 4, "nasa_tlx": 60, "verbatim_quotes": ["I want a non-technical overview of how my agents are working together.", "The concept is powerful but I\u2019m afraid to break something."]}}, {"participant_id": "P5", "profile": {"experience_level": "Beginner", "role": "Operations / Analyst"}, "task_outcomes": {"T1": {"success": false, "time_on_task_seconds": 510, "errors": 2, "assistance_requests": 2, "notes": "Struggled with initial setup; did not understand why multiple agents were needed."}, "T2": {"success": false, "time_on_task_seconds": 540, "errors": 3, "assistance_requests": 2, "notes": "Could not confidently modify flow; labels like 'routing policy' were unclear."}, "T3": {"success": false, "time_on_task_seconds": 720, "errors": 4, "assistance_requests": 2, "notes": "Debugging felt like reading logs from a dev tool; too technical."}, "T4": {"success": false, "time_on_task_seconds": 600, "errors": 3, "assistance_requests": 2, "notes": "Did not complete integration setup; worried about permissions and security."}, "T5": {"success": false, "time_on_task_seconds": 600, "errors": 3, "assistance_requests": 2, "notes": "Could not interpret graphs and metrics; wanted simple success/failure counts."}}, "subjective_feedback": {"system_usability_scale": 60, "satisfaction_1_7": 3, "nasa_tlx": 70, "verbatim_quotes": ["I would need a lot of help to use this day to day.", "I\u2019m not sure what\u2019s safe to change and what\u2019s not."]}}]}, "issues": {"critical": [{"id": "C1", "description": "Debugging orchestration runs is difficult for non-technical users; error sources (agent vs tool vs orchestration logic) are unclear.", "evidence": ["3/5 participants failed T3", "Multiple participants described logs as 'intimidating' or 'too technical'"], "impact": "High", "frequency": "High", "recommendation": "Introduce a simplified debug timeline with clear labels for agent, tool, and orchestration errors; add human-readable summaries and guided suggestions for fixes."}, {"id": "C2", "description": "Conceptual model of agents vs tools vs orchestration is unclear for beginners.", "evidence": ["2/5 participants confused agents with tools", "Beginner participants did not understand why multiple agents were needed"], "impact": "High", "frequency": "Medium", "recommendation": "Add onboarding walkthrough that visually explains agents, tools, and orchestration; use consistent, plain-language labels and contextual help/tooltips."}], "major": [{"id": "M1", "description": "Editing existing orchestrations feels hidden and overly click-heavy.", "evidence": ["2/5 participants failed T2", "Participants expected more direct manipulation on the orchestration graph"], "impact": "Medium", "frequency": "High", "recommendation": "Enable inline editing of conditions and connections directly on the orchestration diagram; surface an explicit 'Edit flow' entry point on the main screen."}, {"id": "M2", "description": "Metrics and analytics are hard to interpret; users lack confidence in making optimization changes.", "evidence": ["3/5 participants failed T5", "Participants requested simpler summaries and before/after comparisons"], "impact": "Medium", "frequency": "High", "recommendation": "Add a simplified metrics overview with plain-language insights and show before/after comparisons when changes are made to the orchestration."}, {"id": "M3", "description": "Tool/integration configuration feels technical and security implications are unclear.", "evidence": ["2/5 participants failed T4", "Questions about API keys, scopes, and where secrets are stored"], "impact": "Medium", "frequency": "Medium", "recommendation": "Create a guided tool-connection wizard, clarify how secrets are stored, and provide non-technical explanations of scopes and permissions."}], "minor": [{"id": "m1", "description": "Some labels (e.g., 'routing policy', 'handoff efficiency') are not self-explanatory.", "evidence": ["Multiple participants asked what specific metrics and labels meant"], "impact": "Low", "frequency": "High", "recommendation": "Rename or supplement technical labels with plain-language descriptions and hover tooltips."}, {"id": "m2", "description": "Uncertainty about save vs publish states when modifying orchestrations.", "evidence": ["At least one participant was unsure if changes were live", "Users looked for an explicit 'publish' step"], "impact": "Low", "frequency": "Medium", "recommendation": "Clarify state with a visible 'Draft/Published' indicator and explicit publish action, plus autosave status indicators."}]}, "recommendations": {"priority_order": ["C1", "C2", "M1", "M2", "M3", "m1", "m2"], "short_term_changes": ["Add contextual tooltips and inline help explaining agents, tools, and orchestration flows.", "Simplify debug view with clearer labels and a high-level summary of where failures occur.", "Improve label clarity for metrics and routing concepts with plain-language alternatives."], "mid_term_changes": ["Redesign orchestration editor to support inline editing on the graph and clearer entry points for modifying existing flows.", "Introduce a guided integration setup experience with explicit explanations of security and permissions.", "Add a simplified analytics overview with recommended optimizations and before/after comparisons."], "long_term_opportunities": ["Provide role-based views (e.g., PM vs Engineer) with different levels of detail and complexity.", "Implement versioning and change history for orchestrations, including rollbacks and diff views.", "Offer a 'safe sandbox' mode for experimentation without impacting production orchestrations."]}, "conclusion": {"summary": "The multi-agent orchestration prototype demonstrates strong potential and is usable for technical users, but non-technical and beginner users struggle with conceptual understanding, debugging, and analytics. Core workflows such as creating and editing orchestrations work but require more direct manipulation and clearer guidance.", "overall_usability_assessment": "Moderate usability with a noticeable learning curve; suitable for early adopters and technical teams but not yet ready for broad non-technical audiences without additional onboarding and simplification."}}, "cost": 0.02, "budget_spent": 0.02, "session_start": "2025-11-16T21:47:04.920387"}
